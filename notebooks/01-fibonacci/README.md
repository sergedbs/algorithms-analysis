# **üìå Empirical Analysis of Fibonacci Algorithms**

## **üìñ Overview**

This study explores and compares different algorithms for computing the **Fibonacci sequence**. The goal is to analyze the **efficiency, scalability, and execution time** of multiple approaches ranging from na√Øve recursion to matrix exponentiation.

The Fibonacci sequence is defined as:

$$
F(n) =
\begin{cases}
    0, & n = 0 \\
    1, & n = 1 \\
    F(n-1) + F(n-2), & n \geq 2
\end{cases}
$$

Various computational methods are implemented and evaluated to determine their suitability for different problem sizes.

## **üéØ Objectives**

- Implement and compare six different Fibonacci algorithms.
- Measure and analyze their empirical performance.
- Identify the most efficient method for varying input sizes.
- Visualize execution time trends through graphs.

## **üõ† Implemented Fibonacci Methods**

### **1Ô∏è‚É£ Na√Øve Recursive Approach** *(Exponential $`O(2^n)`$)*

- Implements the basic recursive definition of Fibonacci.
- **Highly inefficient** for large $n$ due to redundant computations.

### **2Ô∏è‚É£ Recursive with Memoization** *(Top-Down DP, $`O(n)`$)*

- Uses a **cache (dictionary)** to store previously computed values.
- **Reduces redundant calculations** significantly.
- **Linear time complexity** $O(n)$.

### **3Ô∏è‚É£ Iterative Dynamic Programming** *(Bottom-Up DP, $`O(n)`$)*

- Builds the Fibonacci sequence **iteratively** in an array.
- Eliminates recursion overhead but requires **$O(n)$ space**.

### **4Ô∏è‚É£ Matrix Exponentiation** *(Logarithmic $`O(\log n)`$)*

- Uses **matrix multiplication** to compute Fibonacci numbers efficiently.
- **Best method for very large values of $n$**.
- **Logarithmic time complexity** $O(\log n)$.

### **5Ô∏è‚É£ Binet‚Äôs Formula** *(Constant $`O(1)`$)*

- Uses the **Golden Ratio (Phi)** for a closed-form solution.
- **Extremely fast but unreliable** for large $n$ due to floating-point precision errors.

### **6Ô∏è‚É£ Binet's Formula with Decimal Precision** *(Constant $`O(1)`$)*

- Uses the `decimal` module for higher precision arithmetic.
- **More reliable for large values of $n$**.

### **7Ô∏è‚É£ Optimized Iterative Approach** *(Linear $`O(n)`$, Constant Space $`O(1)`$)*

- **Stores only the last two computed values**, reducing memory usage.
- **Most memory-efficient iterative approach**.

### **8Ô∏è‚É£ Fast Doubling Method** *(Logarithmic $`O(\log n)`$)*

- Utilizes a **fast doubling technique** to compute Fibonacci numbers.
- **Achieves logarithmic time complexity** $O(\log n)$.

## **üî¨ Experimental Setup**

### **üìå Input Data**

- **Small Inputs**: $n = \{1, 2, 3, \ldots, 198\}$
- **Large Inputs**: $n = \{200, 300, 400, \ldots, 20000\}$

### **üìå Performance Measurement**

- **Each algorithm** is executed **multiple times** for each input size.
- **Execution time** is recorded using Python‚Äôs `time` module.
- **Results are stored in a CSV file** (`results.csv`).
- **Graphs are generated** to visualize performance trends.

## **üìå Conclusion**

This study provides valuable insights into **choosing the right algorithm** for computing Fibonacci numbers. The findings include:

- **Recursive approach** is highly inefficient and **should be avoided** for large $n$.
- **Memoization & Iterative DP** provide a **linear-time solution** but require additional space.
- **Matrix Exponentiation** is the **fastest method for very large values of $n$**.
- **Binet‚Äôs Formula** is **only reliable for small $n$** due to floating-point errors.
- **Optimized Iterative $O(1)$ Space Method** provides a **good balance between efficiency and memory usage**.
- **Fast Doubling Method** is highly efficient for large $n$.

### **üöÄ Best Algorithm for Different Use Cases**

| **Use Case**                   | **Recommended Algorithm**              |
|--------------------------------|----------------------------------------|
| **Small $n \leq 30$**          | Recursive (for learning purposes)      |
| **Moderate $n < 10^5$**        | Memoization (Top-Down DP)              |
| **Large $n < 10^6$**           | Iterative DP or Optimized Iterative    |
| **Very Large $n > 10^6$**      | Matrix Exponentiation or Fast Doubling |
| **Quick Approximation Needed** | Binet‚Äôs Formula (for small $n$)        |

---

## **üíæ Running the tests**

### **üì• Clone the Repository**

```bash
git clone https://github.com/sergedbs/algorithms-analysis.git
cd algorithms-analysis
```

### **üõ† Install Dependencies** _(if not already installed)_
The dependencies can be installed using either method:

```bash
# Method 1: Using pip with requirements.txt
pip install -r requirements.txt

# Method 2: Install as a package (development mode)
pip install -e .
```

### **‚ñ∂Ô∏è Run the Jupyter Notebook**

```bash
cd notebooks/01-fibonacci
jupyter notebook 01-fibonacci.ipynb
```

### **üìä View Results**

- Check the **CSV file**: `result/results.csv`
- View **performance graphs**: `result/plots/`

## **üìÇ Project Structure**

```plaintext
üìÇ 01-fibonacci/
‚îÇ‚îÄ‚îÄ üìì 01-fibonacci.ipynb          # Jupyter Notebook implementation
‚îÇ‚îÄ‚îÄ üìÇ result/                     # Performance results and visualizations
‚îÇ   ‚îú‚îÄ‚îÄ üìä results.csv             # Execution time results
‚îÇ   ‚îî‚îÄ‚îÄ üìÇ plots/                  # Graphs for performance analysis
‚îî‚îÄ‚îÄ üìÑ README.md                   # This file
```

> This study is part of the _**Empirical Analysis of Algorithms**_ repository. The complete source code and Jupyter notebooks are available on GitHub: [Empirical Analysis of Algorithms](https://github.com/sergedbs/algorithms-analysis).

---
